# -*- coding: utf-8 -*-
"""modeloImagens

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yLcXyH-vMcUz4lZaiYr_dHUhgVXEva91

# Parâmetros do Modelo e Treinamento
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import kagglehub # Para baixar o dataset
import pathlib # Para lidar com caminhos de arquivo
import json # Para salvar os nomes das classes

# --- Parâmetros do Modelo e Treinamento ---
batch_size = 64
altura = 50
largura = 50
epocas = 10 # Número de épocas de treinamento

# Definindo a semente para reprodutibilidade
tf.random.set_seed(424242)

print("Versão do TensorFlow:", tf.__version__)
print("Iniciando treinamento do modelo de gestos...")

# --- 1. Carregamento do Dataset de Imagens de Gestos ---
print("\nBaixando o dataset 'sign-language-gesture-images-dataset' do KaggleHub...")
try:
    path_download = kagglehub.dataset_download("ahmedkhanak1995/sign-language-gesture-images-dataset")
    print(f"Dataset baixado para: {path_download}")

    # O diretório de dados principal dentro do download
    data_dir = pathlib.Path(path_download) / 'Gesture Image Data'

    if not data_dir.exists():
        raise FileNotFoundError(f"Diretório esperado '{data_dir}' não encontrado após download.")

    total_images = len(list(data_dir.glob('*/*.jpg')))
    print(f"Total de imagens encontradas: {total_images}")

    # Verificando a quantidade de imagens em cada subpasta e suas dimensões
    subfolders = [f.name for f in data_dir.iterdir() if f.is_dir()]
    if not subfolders:
        raise ValueError("Nenhuma subpasta encontrada. O dataset pode não estar na estrutura esperada.")

    for subfolder in sorted(subfolders): # Ordenar para consistência
        sub_path = data_dir / subfolder
        images = list(sub_path.glob('*.jpg'))
        print(f"Classe '{subfolder}' tem {len(images)} imagens.")
        if images and total_images > 0: # Evitar erro se não houver imagens
            # Verificar dimensões da primeira imagem (se houver)
            try:
                img = tf.keras.utils.load_img(str(images[0]))
                img_array = tf.keras.utils.img_to_array(img)
                print(f"Dimensões da primeira imagem em '{subfolder}': {img_array.shape}")
            except Exception as e:
                print(f"Aviso: Não foi possível carregar a imagem de exemplo em '{subfolder}': {e}")
        else:
            print(f"Aviso: Nenhuma imagem encontrada na subpasta '{subfolder}'.")


except Exception as e:
    print(f"Erro ao carregar o dataset: {e}")
    print("Verifique se você tem acesso ao KaggleHub ou se o dataset está na estrutura esperada.")
    exit() # Interrompe a execução se não conseguir carregar os dados

# Carregando as imagens do diretório e dividindo em conjuntos de treino e validação
treino_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2, # Divisão de 20% para validação
    subset='training',    # Subconjunto de treino
    seed=568,             # Semente para reprodutibilidade
    image_size=(altura, largura), # Redimensiona as imagens para 50x50
    batch_size=batch_size
)

validacao_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='validation',  # Subconjunto de validação
    seed=568,
    image_size=(altura, largura),
    batch_size=batch_size
)

class_names = treino_ds.class_names
num_classes = len(class_names)
print(f"\nClasses detectadas: {class_names}")
print(f"Número total de classes: {num_classes}")

# Otimização do pipeline de dados
AUTOTUNE = tf.data.AUTOTUNE
treino_ds = treino_ds.cache().prefetch(buffer_size=AUTOTUNE)
validacao_ds = validacao_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""###2. Definição do Callback Personalizado (Opcional, mas útil)"""

# --- 2. Definição do Callback Personalizado (Opcional, mas útil) ---
class MyCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') is not None and logs.get('accuracy') >= 0.95):
      print("\nAlcançamos 95% de acurácia de treino. Parando o treinamento!")
      self.model.stop_training = True

callbacks = [MyCallback()] # Use a classe MyCallback definida acima
# Você pode adicionar também EarlyStopping e ReduceLROnPlateau do Keras:
# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)
# callbacks = [early_stopping, reduce_lr, MyCallback()]

"""###3. Data Augmentation (Aumento de Dados)"""

# --- 3. Data Augmentation (Aumento de Dados) ---
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal"),
  tf.keras.layers.RandomRotation(0.1),
  tf.keras.layers.RandomZoom(0.1),
  tf.keras.layers.RandomContrast(0.1)
])

"""###4. Construção do Modelo CNN"""

# --- 4. Construção do Modelo CNN ---
modelo = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(altura, largura, 3)),
    data_augmentation, # Camada de aumento de dados (apenas durante o treino, deterministicamente na inferência)
    tf.keras.layers.Rescaling(1./255), # Normaliza os pixels para o range [0, 1]

    # Camadas de Convolução e Max Pooling
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), # Adicionada camada extra para mais complexidade
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), # Adicionada camada extra
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'), # Usando 'relu' como string
    tf.keras.layers.Dropout(0.5), # Aumentei o dropout para regularização

    # Camada de Saída: num_classes neurônios com ativação softmax para classificação multi-classe
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# Compilando o modelo
modelo.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),
    loss='sparse_categorical_crossentropy', # Adequado para labels inteiros
    metrics=['accuracy']
)

modelo.summary() # Exibe o resumo do modelo

"""###5. Treinamento do Modelo"""

# --- 5. Treinamento do Modelo ---
print(f"\nIniciando treinamento por {epocas} épocas...")
history = modelo.fit(
    treino_ds,
    validation_data=validacao_ds,
    epochs=epocas,
    callbacks=callbacks # Adicionando o callback
)
print("Treinamento concluído.")

"""###6. Plotar Resultados do Treinamento"""

# --- 6. Plotar Resultados do Treinamento ---
def plota_resultados(history, epocas_treinadas):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    intervalo_epocas = range(epocas_treinadas)

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(intervalo_epocas, acc, label='Acurácia do Treino')
    plt.plot(intervalo_epocas, val_acc, label='Acurácia da Validação')
    plt.legend(loc='lower right')
    plt.title('Acurácia do Treino e Validação')
    plt.xlabel('Época')
    plt.ylabel('Acurácia')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(intervalo_epocas, loss, label='Custo do Treino')
    plt.plot(intervalo_epocas, val_loss, label='Custo da Validação')
    plt.legend(loc='upper right')
    plt.title('Custo do Treino e Validação')
    plt.xlabel('Época')
    plt.ylabel('Custo')
    plt.grid(True)
    plt.show()

plota_resultados(history, len(history.history['accuracy'])) # Passa o número real de épocas treinadas

"""###7. Salvar o Modelo Treinado e Nomes das Classes"""

# --- 7. Salvar o Modelo Treinado e Nomes das Classes ---
model_save_path = 'meu_modelo_gestos.keras'
class_names_save_path = 'class_names.json'

# Salvar o modelo completo no formato Keras v3
modelo.save(model_save_path)
print(f"\nModelo salvo em: {model_save_path}")

# Salvar os nomes das classes para uso no aplicativo Streamlit
with open(class_names_save_path, 'w') as f:
    json.dump(class_names, f)
print(f"Nomes das classes salvos em: {class_names_save_path}")

print("\nTreinamento e salvamento concluídos com sucesso!")
print("Faça o download de 'meu_modelo_gestos.keras' e 'class_names.json' para usar com o Streamlit.")

